{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWgNVRLV0jBqTWjWA0KaZG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shkabh/PUS2024_SKaur/blob/main/12_10_24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ws5i8DTKXdfM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")"
      ],
      "metadata": {
        "id": "6BRiy_97ZukS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkYmrERqZ4LR",
        "outputId": "794e6d68-1a14-4ff2-a2d1-7ddbd0015cac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3601, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-hoXzsxZ5wk",
        "outputId": "a41ab798-7bf9-4629-b826-b35c0525c61d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train[:, :, None]\n",
        "x_test = x_test[:, :, None]"
      ],
      "metadata": {
        "id": "y9UkAgDrZ_FK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY3eyRewaekb",
        "outputId": "a7cdf7be-ee4c-4ddf-9ef9-f9dd0cc73747"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3601, 500, 1), (1320, 500, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(np.unique(y_train))\n",
        "n_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THIJ_FzVaxiS",
        "outputId": "8e2f3efb-0f89-450f-f5c8-921e279f4aed"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.random.permutation(x_train.shape[0])\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0"
      ],
      "metadata": {
        "id": "fzzVb1zGbBjo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eePo4ejsbude",
        "outputId": "a9d63651-3d67-4014-ab76-04816c018a63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-nlp in /usr/local/lib/python3.10/dist-packages (0.18.1)\n",
            "Requirement already satisfied: keras-hub==0.18.1 in /usr/local/lib/python3.10/dist-packages (from keras-nlp) (0.18.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (2024.9.11)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (13.9.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (0.3.4)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (4.66.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: typing-extensions<5.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (4.12.2)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.18.1->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.5.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2024.8.30)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.45.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.13.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_encoder(inputs):\n",
        "  x = layers.LayerNormalization(epsilon = 1e-6)(inputs)\n",
        "  x = layers.MultiHeadAttention(key_dim = 8, num_heads = 8, dropout = 0)(x, x)\n",
        "  res = x + inputs\n",
        "\n",
        "  x = layers.LayerNormalization(epsilon = 1e-6)(res)\n",
        "  x = layers.Conv1D(filters = 2000, kernel_size = 1, activation = \"relu\")(x)\n",
        "  x = layers.Conv1D(filters = inputs.shape[-1], kernel_size = 1)(x)\n",
        "\n",
        "  return res + x\n",
        "\n",
        "def build_model(input_shape, n_classes):\n",
        "  inputs = keras.Input(shape = input_shape)\n",
        "  x = inputs\n",
        "\n",
        "  x = transformer_encoder(x)\n",
        "  x = transformer_encoder(x)\n",
        "\n",
        "  x = layers.GlobalMaxPooling1D(data_format = \"channels_last\")(x)\n",
        "\n",
        "  x = layers.Dense(256, activation = \"relu\")(x)\n",
        "  x = layers.Dense(50, activation = \"relu\")(x)\n",
        "\n",
        "  outputs = layers.Dense(n_classes, activation = \"softmax\")(x)\n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "9LLub4Btb2cl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "model = build_model(input_shape, n_classes)"
      ],
      "metadata": {
        "id": "4iKE0fKNgWVt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "K9u5e1OtggVk",
        "outputId": "9463a951-a01f-4929-e279-4d77310355bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m449\u001b[0m │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization[\u001b[38;5;34m0\u001b[0m… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (\u001b[38;5;33mAdd\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention[\u001b[38;5;34m…\u001b[0m │\n",
              "│                           │                        │                │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m4,000\u001b[0m │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m2,001\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],             │\n",
              "│                           │                        │                │ conv1d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │            \u001b[38;5;34m449\u001b[0m │ layer_normalization_2… │\n",
              "│ (\u001b[38;5;33mMultiHeadAttention\u001b[0m)      │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ multi_head_attention_… │\n",
              "│                           │                        │                │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m2\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mLayerNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m2000\u001b[0m)      │          \u001b[38;5;34m4,000\u001b[0m │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m2,001\u001b[0m │ conv1d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m500\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
              "│                           │                        │                │ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │              \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │            \u001b[38;5;34m512\u001b[0m │ global_max_pooling1d[\u001b[38;5;34m…\u001b[0m │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m12,850\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m102\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">449</span> │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                           │                        │                │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │ layer_normalization_1… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,001</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],             │\n",
              "│                           │                        │                │ conv1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_2     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ multi_head_attention_1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │            <span style=\"color: #00af00; text-decoration-color: #00af00\">449</span> │ layer_normalization_2… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttention</span>)      │                        │                │ layer_normalization_2… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_attention_… │\n",
              "│                           │                        │                │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ layer_normalization_3     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2000</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">4,000</span> │ layer_normalization_3… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">2,001</span> │ conv1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">500</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
              "│                           │                        │                │ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_max_pooling1d      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ global_max_pooling1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">12,850</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,372\u001b[0m (103.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,372</span> (103.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,372\u001b[0m (103.02 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,372</span> (103.02 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = \"sparse_categorical_crossentropy\",\n",
        "    optimizer = keras.optimizers.Adam(learning_rate = 1e-4),\n",
        "    metrics = [\"sparse_categorical_accuracy\"],\n",
        ")"
      ],
      "metadata": {
        "id": "y3jxgCyLhl8S"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(patience = 10, restore_best_weights= True),\n",
        "]"
      ],
      "metadata": {
        "id": "d347UhL9iDLa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    validation_split = 0.2,\n",
        "    epochs = 100,\n",
        "    batch_size = 12,\n",
        "    verbose = 2,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_zqFKMRiMkE",
        "outputId": "b0ade1ba-5e81-4974-9e59-e80e825f07f1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "240/240 - 24s - 101ms/step - loss: 0.6951 - sparse_categorical_accuracy: 0.4962 - val_loss: 0.6916 - val_sparse_categorical_accuracy: 0.5326\n",
            "Epoch 2/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6936 - sparse_categorical_accuracy: 0.5045 - val_loss: 0.6952 - val_sparse_categorical_accuracy: 0.4674\n",
            "Epoch 3/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6927 - sparse_categorical_accuracy: 0.5191 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.5326\n",
            "Epoch 4/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6941 - sparse_categorical_accuracy: 0.4934 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.5284\n",
            "Epoch 5/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.5049 - val_loss: 0.6922 - val_sparse_categorical_accuracy: 0.5381\n",
            "Epoch 6/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6940 - sparse_categorical_accuracy: 0.4958 - val_loss: 0.6940 - val_sparse_categorical_accuracy: 0.4674\n",
            "Epoch 7/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6935 - sparse_categorical_accuracy: 0.4913 - val_loss: 0.6915 - val_sparse_categorical_accuracy: 0.5284\n",
            "Epoch 8/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.5063 - val_loss: 0.6924 - val_sparse_categorical_accuracy: 0.5506\n",
            "Epoch 9/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6933 - sparse_categorical_accuracy: 0.5115 - val_loss: 0.6917 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 10/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6929 - sparse_categorical_accuracy: 0.5049 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.5284\n",
            "Epoch 11/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6934 - sparse_categorical_accuracy: 0.5198 - val_loss: 0.6920 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 12/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6932 - sparse_categorical_accuracy: 0.5052 - val_loss: 0.6907 - val_sparse_categorical_accuracy: 0.5298\n",
            "Epoch 13/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.5122 - val_loss: 0.6923 - val_sparse_categorical_accuracy: 0.5409\n",
            "Epoch 14/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6929 - sparse_categorical_accuracy: 0.5104 - val_loss: 0.6910 - val_sparse_categorical_accuracy: 0.5257\n",
            "Epoch 15/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5146 - val_loss: 0.6913 - val_sparse_categorical_accuracy: 0.5548\n",
            "Epoch 16/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6930 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.6911 - val_sparse_categorical_accuracy: 0.5492\n",
            "Epoch 17/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6928 - sparse_categorical_accuracy: 0.5063 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 18/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.5198 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 19/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.5087 - val_loss: 0.6896 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 20/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6923 - sparse_categorical_accuracy: 0.5163 - val_loss: 0.6905 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 21/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6924 - sparse_categorical_accuracy: 0.5063 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.5506\n",
            "Epoch 22/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6925 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.6899 - val_sparse_categorical_accuracy: 0.5326\n",
            "Epoch 23/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6923 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 24/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5299 - val_loss: 0.6892 - val_sparse_categorical_accuracy: 0.5368\n",
            "Epoch 25/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6924 - sparse_categorical_accuracy: 0.5160 - val_loss: 0.6901 - val_sparse_categorical_accuracy: 0.5562\n",
            "Epoch 26/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6895 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 27/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5184 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.5368\n",
            "Epoch 28/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.6889 - val_sparse_categorical_accuracy: 0.5270\n",
            "Epoch 29/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5306 - val_loss: 0.6890 - val_sparse_categorical_accuracy: 0.5257\n",
            "Epoch 30/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5146 - val_loss: 0.6903 - val_sparse_categorical_accuracy: 0.5534\n",
            "Epoch 31/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5167 - val_loss: 0.6900 - val_sparse_categorical_accuracy: 0.5548\n",
            "Epoch 32/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6922 - sparse_categorical_accuracy: 0.5191 - val_loss: 0.6887 - val_sparse_categorical_accuracy: 0.5368\n",
            "Epoch 33/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5344 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 34/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5201 - val_loss: 0.6893 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 35/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5177 - val_loss: 0.6906 - val_sparse_categorical_accuracy: 0.5492\n",
            "Epoch 36/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6921 - sparse_categorical_accuracy: 0.5260 - val_loss: 0.6891 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 37/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5163 - val_loss: 0.6897 - val_sparse_categorical_accuracy: 0.5548\n",
            "Epoch 38/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5257 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.5423\n",
            "Epoch 39/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5319 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 40/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5215 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5257\n",
            "Epoch 41/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5281 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5368\n",
            "Epoch 42/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 43/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5281 - val_loss: 0.6886 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 44/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6917 - sparse_categorical_accuracy: 0.5260 - val_loss: 0.6872 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 45/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5264 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 46/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5194 - val_loss: 0.6879 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 47/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 48/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6919 - sparse_categorical_accuracy: 0.5316 - val_loss: 0.6883 - val_sparse_categorical_accuracy: 0.5520\n",
            "Epoch 49/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5253 - val_loss: 0.6874 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 50/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6916 - sparse_categorical_accuracy: 0.5271 - val_loss: 0.6884 - val_sparse_categorical_accuracy: 0.5603\n",
            "Epoch 51/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5278 - val_loss: 0.6885 - val_sparse_categorical_accuracy: 0.5631\n",
            "Epoch 52/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5271 - val_loss: 0.6902 - val_sparse_categorical_accuracy: 0.5506\n",
            "Epoch 53/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5333 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 54/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5271 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5506\n",
            "Epoch 55/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5205 - val_loss: 0.6894 - val_sparse_categorical_accuracy: 0.5465\n",
            "Epoch 56/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5226 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5534\n",
            "Epoch 57/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5125 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.5326\n",
            "Epoch 58/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5219 - val_loss: 0.6878 - val_sparse_categorical_accuracy: 0.5479\n",
            "Epoch 59/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5212 - val_loss: 0.6877 - val_sparse_categorical_accuracy: 0.5465\n",
            "Epoch 60/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5292 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5326\n",
            "Epoch 61/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5260 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 62/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5233 - val_loss: 0.6864 - val_sparse_categorical_accuracy: 0.5354\n",
            "Epoch 63/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6918 - sparse_categorical_accuracy: 0.5229 - val_loss: 0.6870 - val_sparse_categorical_accuracy: 0.5465\n",
            "Epoch 64/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5222 - val_loss: 0.6873 - val_sparse_categorical_accuracy: 0.5548\n",
            "Epoch 65/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5267 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5312\n",
            "Epoch 66/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5278 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.5340\n",
            "Epoch 67/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6920 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 68/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5219 - val_loss: 0.6869 - val_sparse_categorical_accuracy: 0.5548\n",
            "Epoch 69/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5247 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 70/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5243 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 71/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5292 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5368\n",
            "Epoch 72/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5247 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 73/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6863 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 74/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6915 - sparse_categorical_accuracy: 0.5285 - val_loss: 0.6871 - val_sparse_categorical_accuracy: 0.5603\n",
            "Epoch 75/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5264 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5548\n",
            "Epoch 76/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5295 - val_loss: 0.6880 - val_sparse_categorical_accuracy: 0.5520\n",
            "Epoch 77/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5323 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.5298\n",
            "Epoch 78/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5226 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 79/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5312 - val_loss: 0.6875 - val_sparse_categorical_accuracy: 0.5520\n",
            "Epoch 80/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 81/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5257 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.5284\n",
            "Epoch 82/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5288 - val_loss: 0.6865 - val_sparse_categorical_accuracy: 0.5562\n",
            "Epoch 83/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6914 - sparse_categorical_accuracy: 0.5233 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5617\n",
            "Epoch 84/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5316 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 85/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5319 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.5368\n",
            "Epoch 86/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5250 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 87/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5288 - val_loss: 0.6868 - val_sparse_categorical_accuracy: 0.5603\n",
            "Epoch 88/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5201 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.5492\n",
            "Epoch 89/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5312 - val_loss: 0.6859 - val_sparse_categorical_accuracy: 0.5284\n",
            "Epoch 90/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5253 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.5437\n",
            "Epoch 91/100\n",
            "240/240 - 7s - 27ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5233 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5631\n",
            "Epoch 92/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5288 - val_loss: 0.6866 - val_sparse_categorical_accuracy: 0.5603\n",
            "Epoch 93/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5274 - val_loss: 0.6862 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 94/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5271 - val_loss: 0.6858 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 95/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6912 - sparse_categorical_accuracy: 0.5226 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 96/100\n",
            "240/240 - 6s - 26ms/step - loss: 0.6911 - sparse_categorical_accuracy: 0.5243 - val_loss: 0.6881 - val_sparse_categorical_accuracy: 0.5506\n",
            "Epoch 97/100\n",
            "240/240 - 6s - 27ms/step - loss: 0.6910 - sparse_categorical_accuracy: 0.5351 - val_loss: 0.6867 - val_sparse_categorical_accuracy: 0.5506\n",
            "Epoch 98/100\n",
            "240/240 - 10s - 43ms/step - loss: 0.6908 - sparse_categorical_accuracy: 0.5354 - val_loss: 0.6856 - val_sparse_categorical_accuracy: 0.5451\n",
            "Epoch 99/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6909 - sparse_categorical_accuracy: 0.5323 - val_loss: 0.6861 - val_sparse_categorical_accuracy: 0.5576\n",
            "Epoch 100/100\n",
            "240/240 - 10s - 42ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5181 - val_loss: 0.6857 - val_sparse_categorical_accuracy: 0.5437\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7957058f9a50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhFM2TePiOFK"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}